---
title: "p8105_hw6_fc2691"
author: "fc2691"
date: "11/27/2021"
output: github_document
---
```{r set up, include=FALSE}
library(tidyverse)
library(knitr)
library(modelr)
library(mgcv)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```
## Problem 1
```{r import data}
birth_data <- read.csv("./birthweight.csv") %>% 
  janitor::clean_names()
str(birth_data)
```

```{r clean data}
#Change numeric to factors appropriately
col_fac <- c(1, 7, 9, 13:16) 
birth_data[,col_fac] <- lapply(birth_data[,col_fac] , factor)
str(birth_data)

kable(birth_data[1:10,])

#Checking for missing data
sum(is.na(birth_data))
options(na.action = na.warn)

#Take a look at the birthweight distribution
summary(birth_data$bwt)
hist(birth_data$bwt, main = "Histogram of birthweight", xlab = "Birthweight") 
```
There is no missing data in this database. 
The data mean number is nearly same as the median number. With the combination of histogram, birthweight parameter nearly follows the normal distribution.  

After cleaning the dataset, I use backward elimination to select variables(predictions) and build regression models. 
```{r regression model for birthweight}
# Prepare data for linear model
birth_prep <- 
  birth_data %>% 
  select(-babysex, -frace, -malform, -mrace, -parity, -pnumlbw, -pnumsga, -wtgain)

# Fit using all predictors
birth_model = lm(bwt ~ ., data = birth_prep)
summary(birth_model)

#Take out ppbmi
birth_model = update(birth_model, . ~ . -ppbmi)
summary(birth_model)

#Take out menarche
birth_model = update(birth_model, . ~ . -menarche)
summary(birth_model)

plot(birth_model)

#Tidying output
birth_model %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value)

coef(birth_model)
```
Thus I get the regression model:  
Y = -6560.47+132.41\*bhead+77.37\*blength+4.02\*delwt+1.022\*fincome+13.04\*gaweeks+8.042\*mheight+4.249\*momage+(-2.912)\*ppwt+(-2.902)\*smoken  
Then using add_predictions and add_residuals to diagnostic and make a plot.   
```{r plot of model residuals against fitted values}
birth_data %>% 
  modelr::add_residuals(birth_model) %>%
  modelr::add_predictions(birth_model) %>% 
  select(resid, pred) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point()
```
Now it is time to compare model to two others linear models with different predictors:  

- One using length at birth and gestational age as predictors (main effects only)  
- One using head circumference, length, sex, and all interactions (including the three-way interaction) between these. 
Thus I get the two new linear regression models:  
```{r}
# Linear regression for other two regression models. 
birth_gest_model <- lm(bwt ~ blength + gaweeks, data = birth_data)
summary(birth_gest_model)
head_length_sex_inter_model <- lm(bwt ~ bhead * blength * babysex, data = birth_data)
summary(head_length_sex_inter_model)

# Calculate the cross-validated prediction error. 
cv_birth =
  crossv_mc(birth_data, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

# RMSE and fit models. 
cv_birth <- 
  cv_birth %>% 
  mutate(
    birth_model = map(train, ~lm(bwt ~ bhead + blength + delwt + fincome + gaweeks + mheight + momage + ppwt + smoken, data = .x)), 
    birth_gest_model = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)), 
    head_length_sex_inter_model = map(train, ~lm(bwt ~ bhead * blength * babysex, data = birth_data), data = .x)) %>% 
  mutate(
    rmse_birth = map2_dbl(birth_model, test, ~rmse(model = .x, data = .y)),
    rmse_bir_ges = map2_dbl(birth_gest_model, test, ~rmse(model = .x, data = .y)),
    rmse_hls_inter = map2_dbl(head_length_sex_inter_model, test, ~rmse(model = .x, data = .y)))

# Draw a plot to show RMSE distribution
cv_birth %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```
Compared to two other linear models, the root mean square error with my 9 predictors is the lowest on average. And the rmse difference between my model and that three way interactions is not that largem while models using birthlength and gestational age has the largest rmse overall. After all, my linear regression model the best at predicting observation data among those three.   
## Problem 2  
```{r Download 2017 Central Park Weather Data, message = FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r bootstrapping}
set.seed(1)

# Build bootstrap function
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

boot_sample(weather_df) %>% 
  ggplot(aes(x = tmin, y = tmax)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm") +
  labs(title = "linear regression", x =  "predictor(tmin)", y = "response(tmax)")
```

The plot shows the association between the predictor(tmin) and response(tmax).   
```{r bootstrap analysis}
weather_boot <- 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

# Bootstrap Analysis
weather_results <- 
  weather_boot %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap_sample) %>% 
  unnest(results) %>% 
  select(-std.error, -statistic, -p.value) %>% 
  pivot_wider(names_from = term, 
              values_from = estimate) %>% 
  janitor::clean_names() %>% 
  mutate(log_b0b1 = log(intercept * tmin), 
         r_square = map(models, broom::glance)) %>% 
  select(strap_number, log_b0b1, r_square) %>% 
  unnest(r_square)

```
Then two plots will be shown for those two estimates.  
```{r PLot the distribution of two quantities}
log_b0b1_plot <- 
  weather_results %>% 
  ggplot(aes(x = log_b0b1)) +
  geom_histogram()

log_r_square_plot <- 
  weather_results %>% 
  ggplot(aes(x = r.squared)) +
  geom_histogram()

log_b0b1_plot + log_r_square_plot + plot_annotation(
  title = 'Distribution for log and rsquare')
```
Both logb0b1 and r^2 are nearly normally distributed, and the average value for logb0b1 and r^2 are nearly locate around 2.02 and 0.91 
```{r identify quantiles and find confidence interval}
#95% confidence
weather_results_ci <-
  weather_results %>% 
  summarize(
    r_square_ci_lower = quantile(r.squared, 0.025), 
    r_square_ci_upper = quantile(r.squared, 0.975), 
    log_ci_lower = quantile(log_b0b1, 0.025), 
    log_ci_upper = quantile(log_b0b1, 0.975))
weather_results_ci
```
When trying to find confidence interval for those two estimates with a significance level of 95%. I get confidence interval (0.894, 0.927) for r^2, and confidence interval(1.965, 2.059) for log(b0*b1). 
